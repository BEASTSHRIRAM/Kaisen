# Kaisen - Automated Security Incident Response System

A comprehensive security monitoring and incident response system combining reinforcement learning-based anomaly detection with real-time log collection and attack graph modeling.

## ðŸŽ¯ Project Overview

Kaisen consists of two integrated components:

### 1. RL-Based Anomaly Detection
A reinforcement learning agent that:
- Observes noisy behavioral metrics (login rates, file access patterns, CPU usage, **rate-of-change features**)
- Learns to select defensive actions (block IP, lock account, terminate process, isolate host)
- Responds to attacks early while minimizing false positives
- Operates under uncertainty without knowing the true attack state

### 2. Log Collection Backend
A cross-platform log collection and analysis system that:
- Collects system logs from Windows and Linux machines (local and remote)
- Extracts and tracks IP addresses from network connections
- Processes raw logs into structured feature vectors
- Uses the pre-trained RL model for real-time anomaly detection
- Builds attack graphs to visualize potential attack paths
- Generates alerts with suspicious IP identification
- Provides CLI interface for monitoring and management

## ðŸ“ Project Structure

```
minip/
â”œâ”€â”€ main.py                         # RL training entry point
â”œâ”€â”€ config.json                     # Log collection configuration
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ data/                           # Training datasets
â”‚   â”œâ”€â”€ Monday-WorkingHours.pcap_ISCX.csv
â”‚   â”œâ”€â”€ Tuesday-WorkingHours.pcap_ISCX.csv
â”‚   â””â”€â”€ file.csv
â”œâ”€â”€ src/
â”‚   # RL Components
â”‚   â”œâ”€â”€ config.py                   # RL configuration
â”‚   â”œâ”€â”€ preprocess.py               # Data preprocessing
â”‚   â”œâ”€â”€ attack_simulator.py         # Attack simulation
â”‚   â”œâ”€â”€ incident_env.py             # OpenAI Gym environment
â”‚   â”œâ”€â”€ agent.py                    # DQN agent
â”‚   â”œâ”€â”€ train.py                    # Training script
â”‚   â”œâ”€â”€ evaluate.py                 # Evaluation & visualization
â”‚   # Log Collection Components
â”‚   â”œâ”€â”€ collection_config.py        # Log collection config
â”‚   â”œâ”€â”€ data_models.py              # Data structures
â”‚   â”œâ”€â”€ terminal_executor.py        # Safe command execution
â”‚   â”œâ”€â”€ data_processor.py           # Log parsing & IP extraction
â”‚   â”œâ”€â”€ log_collector.py            # Local log collection
â”‚   â”œâ”€â”€ remote_log_collector.py     # Remote log fetching
â”‚   â”œâ”€â”€ model_interface.py          # Anomaly detection interface
â”‚   â”œâ”€â”€ alert_engine.py             # Alert generation
â”‚   â”œâ”€â”€ graph_engine.py             # Attack graph modeling
â”‚   â”œâ”€â”€ storage_manager.py          # Data persistence
â”‚   â””â”€â”€ log_collection_main.py      # Log collection CLI
â”œâ”€â”€ models/                         # Saved model checkpoints
â”œâ”€â”€ logs/                           # Collected logs & alerts
â”‚   â”œâ”€â”€ history.json                # System metrics history
â”‚   â”œâ”€â”€ alerts.json                 # Generated alerts
â”‚   â””â”€â”€ application.log             # Application logs
â””â”€â”€ tests/                          # Unit & property tests
    â”œâ”€â”€ unit/
    â””â”€â”€ property/
```

## ðŸš€ Quick Start

### Install Dependencies

```bash
pip install -r requirements.txt
```

### RL Training

#### Run Complete Pipeline

```bash
python main.py all --episodes 500
```

This will:
1. Preprocess the datasets
2. Train the RL agent for 500 episodes
3. Generate training visualizations
4. Run a demo showing the trained agent

#### Individual Commands

```bash
# Preprocess datasets
python main.py preprocess

# Train the agent (with all enhancements)
python main.py train --episodes 1000 --n-step --dueling --compare

# Evaluate trained model
python main.py evaluate --analyze-policy

# Generate visualizations
python main.py visualize

# Run interactive demo
python main.py demo --interactive
```

### Log Collection System

#### Configure

Edit `config.json` to set:
- Collection interval (default: 7 seconds)
- Anomaly threshold (default: 0.7)
- Remote endpoints (optional)
- Log file paths

#### Run Log Collection

```bash
# Start continuous monitoring
python src/log_collection_main.py start

# Single collection cycle (for testing)
python src/log_collection_main.py collect-once

# Export attack graph to JSON
python src/log_collection_main.py export-graph
```

#### View Results

```bash
# View collected logs
cat logs/history.json

# View generated alerts
cat logs/alerts.json

# View application logs
cat logs/application.log
```

## ðŸ§  Technical Details

### Enhanced Observation Space (10D)

The environment provides an **enhanced 10-dimensional observation space** for better attack detection:

| Feature | Description | Range |
|---------|-------------|-------|
| `login_rate` | Login attempts per window | [0, 200] |
| `file_access_rate` | File accesses per window | [0, 500] |
| `cpu_usage` | CPU usage percentage | [0, 100] |
| `login_delta` | **Rate of change** in login attempts | [-100, 100] |
| `file_delta` | **Rate of change** in file access | [-200, 200] |
| `cpu_delta` | **Rate of change** in CPU usage | [-50, 50] |
| `login_ma` | **Moving average** of login rate | [0, 200] |
| `file_ma` | **Moving average** of file rate | [0, 500] |
| `sustained_indicator` | **Sustained anomaly** indicator | [0, 1] |
| `normalized_time` | Episode progress | [0, 1] |

> **Note**: Rate-of-change features help detect attack **escalation** patterns.

### Attack Simulation

Two attack types modeled as probabilistic FSMs:

**Brute-Force Attack:**
```
Normal â†’ Probing â†’ Active â†’ Compromised
```

**Ransomware Attack:**
```
Normal â†’ Execution â†’ Encryption â†’ Data Loss
```

### Statistical Modeling

| Approach | Application |
|----------|-------------|
| **Poisson distributions** | Event counts (login attempts, file accesses) |
| **Local rate modeling** | Captures burstiness in network activity |
| **Normal distributions** | CPU usage with N(30,5) normal, N(80,5) attack |

> **Dataset Note**: CICIDS 2017 provides network flow features. `Total Fwd Packets` is used as a proxy for login attempts since explicit authentication logs are unavailable.

### DQN Agent Enhancements

| Feature | Description | Flag |
|---------|-------------|------|
| **Double DQN** | Reduces overestimation bias | Default |
| **N-step Returns** | Better temporal credit assignment | `--n-step` |
| **Dueling Architecture** | Separate value/advantage streams | `--dueling` |
| **Prioritized Replay** | Sample important experiences more | `--prioritized-replay` |

### Reward Structure

```python
rewards = {
    "early_containment": +50,    # Stopped attack in stage 1-2
    "late_containment": +20,     # Stopped attack in stage 3+
    "correct_no_action": +1,     # No action when no attack
    "false_positive": -10,       # Action when no attack
    "missed_attack": -30,        # Attack reached final state
    "step_penalty": -0.1         # Encourages efficiency
}
```

## ðŸ“Š Statistical Significance Testing

The project includes rigorous statistical analysis:

```bash
python main.py train --episodes 500 --compare
```

Outputs include:
- **Welch's t-test** with p-values
- **Cohen's d** effect size
- **95% confidence intervals**
- **Mann-Whitney U test** (non-parametric)

Example output:
```
DQN vs random:
  T-statistic: 8.4521
  P-value: 0.000001
  Cohen's d: 1.23
  95% CI: (12.45, 25.67)
  Significant: âœ“
```

## ðŸ“ˆ Hyperparameter Sensitivity Analysis

Run sensitivity studies on key hyperparameters:

```python
from src.evaluate import HyperparameterAnalyzer
from src.train import Trainer

analyzer = HyperparameterAnalyzer()
results = analyzer.run_sensitivity_study(
    Trainer,
    param_name='learning_rate',
    param_values=[1e-4, 5e-4, 1e-3, 5e-3],
    num_episodes=200,
    num_seeds=3
)
analyzer.plot_sensitivity('learning_rate')
```

## ðŸ”§ Training Options

```bash
python main.py train \
    --episodes 1000 \
    --attack-type random \
    --n-step \
    --n-steps 3 \
    --dueling \
    --checkpoint-dir models \
    --compare
```

| Option | Description | Default |
|--------|-------------|---------|
| `--episodes` | Training episodes | 500 |
| `--attack-type` | bruteforce, ransomware, both, random | random |
| `--n-step` | Enable N-step returns | False |
| `--n-steps` | N for N-step returns | 3 |
| `--dueling` | Use dueling architecture | False |
| `--no-enhanced` | Use 4D observation instead of 10D | False |
| `--compare` | Compare with baselines + statistics | False |

## ðŸ“š References

- CICIDS 2017 Dataset: Canadian Institute for Cybersecurity
- CERT Insider Threat Dataset: Software Engineering Institute
- DQN: Mnih et al., "Human-level control through deep reinforcement learning"
- Double DQN: van Hasselt et al., "Deep Reinforcement Learning with Double Q-learning"
- Dueling DQN: Wang et al., "Dueling Network Architectures for Deep Reinforcement Learning"

## ðŸŽ“ Academic Rigor

This implementation includes features expected in academic work:

- âœ… **Poisson-based simulation** with empirical justification
- âœ… **Statistical significance testing** (t-tests, effect sizes)
- âœ… **Ablation study support** (baseline comparisons)
- âœ… **Hyperparameter sensitivity analysis**
- âœ… **Documented limitations** (proxy features, synthetic attacks)

## ðŸ“„ License

This project is for educational purposes as part of a mini project.
